'''
Copyright 2024 Zhixuan Hu

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
'''

import streamlit as st
from streamlit_modal import Modal

import sys, os, re, math, importlib
from string import Template
os.chdir(os.path.dirname(__file__))
sys.path.append(os.path.join(os.getcwd(), '../'))
supported_models = [model for model in os.listdir('../models') if os.path.isdir(os.path.join('../models', model))]

## åŠ è½½æ¨¡å‹ï¼Œå¯¼å…¥æ¨¡å‹å¯¹åº”çš„inferenceæ¨¡å—
@st.cache_resource
def init_model(model_name):
    pths = os.listdir(os.path.join('../models', model_name, 'pths'))
    inference = importlib.import_module(f"models.{model_name}.inference")
    return pths, inference

## è§„èŒƒå­—ç¬¦ä¸²åˆ°è¾¹æ ä¼šè¯æŒ‰é’®è¦æ±‚
@st.cache_data
def adj_str(input_str, length=18, padding_char='\u3000'):
    actual_length = sum(2 if ord(char) > 127 else 1 for char in input_str)
    if actual_length > length:
        return input_str[:length]
    else:
        return input_str.ljust(length - (actual_length - len(input_str)), padding_char)

## åˆ†å‰²æ–‡æœ¬ä¸ºè¯­æ®µ
@st.cache_data
def split_text_into_segments(text, reg=r'[\n]'):
    # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åˆ†å‰²æ–‡æœ¬ï¼Œåˆ†éš”ç¬¦ä¸ºå¥å·ã€é—®å·æˆ–æ„Ÿå¹å·
    segments = re.split(reg, text)
    # è¿‡æ»¤æ‰ç©ºå­—ç¬¦ä¸²ï¼Œå¹¶åœ¨æ¯ä¸ªæ®µè½ååŠ ä¸ŠåŸæ¥çš„ç»“æŸç¬¦å·
    segments = [seg.strip() for seg in segments if seg.strip() != '']
    return segments

## åˆ é™¤ä¼šè¯
def delete_session(id):
    def delete():
        del st.session_state.history[id]
    # å¼¹å‡ºç¡®è®¤å¯¹è¯æ¡†
    session = st.session_state.history[id]
    msg = Modal(title="#### åˆ é™¤ä¼šè¯", key="delete", max_width=500).container()
    with msg:
        st.markdown(f"ç¡®è®¤åˆ é™¤è¯¥ç”¨ä¾‹ï¼Ÿ \n{session['name']}")
        b1, b2 = st.columns(spec=[1, 6])
        b1.button("ç¡®è®¤", on_click=delete) # ä½¿ç”¨onlickæ‰ä¼šè°ƒç”¨æˆåŠŸå¹¶æˆåŠŸåˆ·æ–°ï¼Œä¸èƒ½ç”¨if
        b2.button("å–æ¶ˆ")

## é‡å‘½åä¼šè¯
def rename_session(id):
    def tru_rename():
        st.session_state.history[id]['name'] = st.session_state['text']
    # å¼¹å‡ºç¡®è®¤å¯¹è¯æ¡†
    def rename():
        st.session_state.text = st.session_state['rename-text'] # è¯»å–è‡ªåŠ¨ä¿å­˜çš„è¾“å…¥æ–‡æœ¬ï¼Œç›®å‰åªèƒ½é‡‡ç”¨æ­¤ç­–ç•¥è¯»åˆ°æ–‡æœ¬
        msg = Modal(title="#### ç¡®è®¤é‡å‘½å", key="confirm-rename", max_width=500).container()
        with msg:
            st.markdown(f"ç¡®è®¤é‡å‘½å  \n`{oldname}`  \nä¸ºï¼š  \n`{st.session_state['text']}`ï¼Ÿ")
            b1, b2 = st.columns(spec=[1, 6])
            b1.button("ç¡®è®¤", on_click=tru_rename)
            b2.button("å–æ¶ˆ")
    # å¼¹å‡ºè¾“å…¥å¯¹è¯æ¡†
    session = st.session_state.history[id]
    oldname = session['name']
    msg = Modal(title="#### é‡å‘½åä¼šè¯", key="rename", max_width=500).container()
    with msg:
        st.text_input(label=" ", key="rename-text", value=session['name'], on_change=rename) # å½“æŒ‰ä¸‹å›è½¦ä¼šè§¦å‘on_change

## æ–°å»ºä¼šè¯
def new_session():
    def create():
        st.session_state.history.append({
            "id": len(st.session_state.history),   # å”¯ä¸€æ ‡è¯†
            'name': st.session_state['new-text'],  # ä¼šè¯åç§°
            "tab_count": 2,                        # tabæ•°é‡
            'data': [{                             # å„ä¸ªtabçš„ä¿å­˜ä¿¡æ¯
                    "model_index": 0,        # é€‰è¿‡çš„æ¨¡å‹id
                    "device_index": 0,       # é€‰è¿‡çš„è®¾å¤‡id
                    "pth_index": 0,          # é€‰è¿‡çš„å‚æ•°id
                }, {
                    "model_index": 0,
                    "device_index": 0,
                    "pth_index": 0,
                },
            ]
        })
    # å¼¹å‡ºè¾“å…¥å¯¹è¯æ¡†
    msg = Modal(title="#### æ–°å»ºä¼šè¯", key="new", max_width=500).container()
    with msg:
        st.text_input(label=" ", key="new-text", value="ä¼šè¯ ", on_change=create)

## é€šè¿‡onchangeè§¦å‘ï¼Œç¼“å­˜é—®é¢˜æ–‡æœ¬
def save_question_text(data, key):
    data['question_text'] = st.session_state[key]

## é€šè¿‡onchangeè§¦å‘ï¼Œç¼“å­˜å›ç­”æ–‡æœ¬
def save_answer_text(data, key):
    data['answer_text'] = st.session_state[key]

class Reporter():
    def __init__(self):
        self.local_templates = {'default': Template("""
            <div style="background-color: ${color}; padding: 10px; margin: 10px 0;">
                <strong>æ®µè½é¢„æµ‹æ¦‚ç‡: ${prob}%</strong>
                <p>${text}</p>
            </div>
        """)}

    # æ ¹æ®æ¦‚ç‡è®¡ç®—é¢œè‰²çš„æ·±åº¦
    def color_gradient(self, prob):
        intensity = 255 - int(math.floor(155 * prob))  # ä¿è¯è‡³å°‘æ˜¯100ï¼Œæ‰€ä»¥é¢œè‰²ä¸ä¼šå¤ªæ·±
        return f"rgb(255, {intensity}, {intensity})"  # çº¢è‰²æ¸å˜
    
    # ç”ŸæˆæŠ¥å‘Š
    def local_render(self, local, segment, probs):
        local_template = self.local_templates[local]
        ans_seg = [
            local_template.substitute(text=text, prob=f"{prob*100:.1f}", color=self.color_gradient(prob))
            for text, prob in list(zip(segment, probs))
        ]
        return "\n".join(ans_seg)
    


























## åˆå§‹åŒ–ï¼Œåˆ›å»ºå†å²ä¼šè¯è®°å½•
if not hasattr(st.session_state, 'history'):
    st.session_state.history = []
if not hasattr(st.session_state, 'current'):
    st.session_state.current = {}

if 'reporter' not in globals():
    reporter = Reporter()

st.set_page_config(page_title="llmFlight", page_icon=' ', layout='wide')

## ä¾§è¾¹æ 
st.sidebar.header("å†å²ä¼šè¯")

for session in st.session_state.history:
    c1, c2, c3 = st.sidebar.columns(spec=[9, 2, 2])
    if c1.button(adj_str(session['name']), key=f"{session['id']}-on"):
        # ç‚¹å‡»ååŠ è½½sessionåˆ°current
        st.session_state.current = session
    c2.button("ğŸ—‘ï¸", key=f"{session['id']}-delete", on_click=delete_session, args=(session['id'],))
    c3.button("ğŸ–‰", key=f"{session['id']}-rename", on_click=rename_session, args=(session['id'],))

st.sidebar.button("ï¼‹ æ–°å»ºä¼šè¯", key="new_session", type="primary", on_click=new_session)

## æ ¹æ®currentåŠ è½½ä¸»ç•Œé¢
if st.session_state.current:
    session = st.session_state.current
    id = session['id']
    st.markdown(f"#### {session['name']}")
    # åŠ è½½å„ä¸ªtab
    for tabid, tab in enumerate(st.tabs([f"Tab{i+1}" for i in range(session['tab_count'])])):
        with tab:
            # é€‰æ‹©æ¨¡å‹ã€è®¾å¤‡ã€å‚æ•°
            data = session['data'][tabid]
            model_name = st.selectbox(label="model", key=f'select-model-{id}-{tabid}', options=supported_models, index=data['model_index'])
            data['model_index'] = supported_models.index(model_name)
            pths, inference = init_model(model_name)
            supported_devices = st.cache_resource(inference.supported_devices)()
            device = st.selectbox(label="device", key=f'select-device-{id}-{tabid}', options=list(supported_devices.keys()), index=data['device_index'])
            data['device_index'] = list(supported_devices.keys()).index(device)
            pth = st.selectbox(label="model params", key=f'select-params-{id}-{tabid}', options=pths, index=data['pth_index'])
            data['pth_index'] = pths.index(pth)
            model = inference.Model(os.path.join("../models", model_name, "pths", pth), supported_devices[device])
            # è¾“å…¥æ–‡æœ¬
            question_text = st.text_area(label="question", value=data.get('question_text', ""), height=100, key=f"question-input-{id}-{tabid}", 
                                         on_change=save_question_text, args=(data, f"question-input-{id}-{tabid}"))
            st.write(f"The text has about `{sum(2 if ord(char) > 127 else 1 for char in question_text)}` tokens.")
            answer_text = st.text_area(label="answer", value=data.get('answer_text', ""), height=500, key=f"answer-input-{id}-{tabid}",
                                       on_change=save_answer_text, args=(data, f"answer-input-{id}-{tabid}"))
            st.write(f"The text has about `{sum(2 if ord(char) > 127 else 1 for char in answer_text)}` tokens.")
            # é¢„æµ‹
            if st.button("æ£€æµ‹", key=f"infer-{id}-{tabid}"):
                question_embedding = inference.get_embeddings([question_text])[0]
                answer_seg = [answer_text] + split_text_into_segments(answer_text)
                answer_embeddings = inference.get_embeddings(answer_seg)
                probs = [model.infer(question_embedding, answer_embedding) for answer_embedding in answer_embeddings]
                st.html(reporter.local_render('default', answer_seg[1:], probs[1:]))
                st.write(probs[0], "inferenced by", device)
































































